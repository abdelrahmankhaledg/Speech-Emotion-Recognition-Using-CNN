{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Imports**","metadata":{}},{"cell_type":"markdown","source":"1-Validation Important\n2-Inception Module \n4-Convert melspectrogram to Image\n5-Increase melspectrogram more than 20 Important\n6-Scheduler\n7-Checkpoint\n9-Changing Architecture \n11-Balancing","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport librosa\nimport librosa.display as libd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import normalize\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pickle\nimport joblib\nfrom sklearn.model_selection import train_test_split\nimport IPython.display as ipd\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.optim import Adam\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:50:55.434082Z","iopub.execute_input":"2022-05-11T21:50:55.434519Z","iopub.status.idle":"2022-05-11T21:50:56.952563Z","shell.execute_reply.started":"2022-05-11T21:50:55.434408Z","shell.execute_reply":"2022-05-11T21:50:56.951519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Importing Data**","metadata":{}},{"cell_type":"code","source":"# emotions = {'SAD' : 'sadness',\n# 'ANG' : 'angry',\n# 'DIS' : 'disgust',\n# 'FEA' : 'fear',\n# 'HAP' : 'happy',\n# 'NEU' : 'neutral'}\nemotions = {'SAD' : 0,\n'ANG' : 1,\n'DIS' : 2,\n'FEA' : 3,\n'HAP' : 4,\n'NEU' : 5}","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:50:56.954981Z","iopub.execute_input":"2022-05-11T21:50:56.955347Z","iopub.status.idle":"2022-05-11T21:50:56.961929Z","shell.execute_reply.started":"2022-05-11T21:50:56.955302Z","shell.execute_reply":"2022-05-11T21:50:56.960788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" audio_data = '../input/speech-emotion-recognition-en/Crema/1028_TSI_DIS_XX.wav'\n x , sr = librosa.load(audio_data)\n print(type(x), type(sr))\n print(x.shape, sr)\naudio_files_names = os.listdir('../input/speech-emotion-recognition-en/Crema')\nnumber_of_audio_files = len(audio_files_names)\ndataset = []\nlabels = []\ncurr = 0\nfor i in range(20):\n    # print('../input/speech-emotion-recognition-en/Crema' + '/' + audio_files_names[i])\n    audio_file_emotion = audio_files_names[i].split('_')[2]\n    x,_ = librosa.load('../input/speech-emotion-recognition-en/Crema' + '/' + audio_files_names[i])\n    dataset.append(x)\n    labels.append(emotions[audio_file_emotion])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:50:56.963526Z","iopub.execute_input":"2022-05-11T21:50:56.963873Z","iopub.status.idle":"2022-05-11T21:50:59.100068Z","shell.execute_reply.started":"2022-05-11T21:50:56.963829Z","shell.execute_reply":"2022-05-11T21:50:59.099239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = np.array(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:50:59.102007Z","iopub.execute_input":"2022-05-11T21:50:59.10238Z","iopub.status.idle":"2022-05-11T21:50:59.106599Z","shell.execute_reply.started":"2022-05-11T21:50:59.102336Z","shell.execute_reply":"2022-05-11T21:50:59.10573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_features(dataset,frame_length,hop_length):\n    features_zcr = []\n    features_rms = []\n    for data_sample in dataset:\n        zcr = librosa.feature.zero_crossing_rate(data_sample,frame_length = frame_length,hop_length = hop_length)\n        print(zcr[0].shape)\n        features_zcr.append(zcr[0])\n        rms = librosa.feature.rms(data_sample,frame_length = frame_length,hop_length = hop_length)\n        print(rms[0].shape)\n        features_rms.append(rms[0])\n    return np.array(features_zcr),np.array(features_rms)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:50:59.108646Z","iopub.execute_input":"2022-05-11T21:50:59.108911Z","iopub.status.idle":"2022-05-11T21:50:59.1215Z","shell.execute_reply.started":"2022-05-11T21:50:59.108884Z","shell.execute_reply":"2022-05-11T21:50:59.120489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_MFCC(dataset):\n    mfcc_feature_space = []\n    for data_sample in dataset:\n        mfccs = librosa.feature.mfcc(y=data_sample)\n        print(mfccs.shape)\n        mfcc_feature_space.append(np.array(mfccs))\n    return (mfcc_feature_space)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:50:59.123462Z","iopub.execute_input":"2022-05-11T21:50:59.123819Z","iopub.status.idle":"2022-05-11T21:50:59.142472Z","shell.execute_reply.started":"2022-05-11T21:50:59.123772Z","shell.execute_reply":"2022-05-11T21:50:59.141167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mfcc_feature_space = extract_MFCC(dataset)\nprint(type(mfcc_feature_space))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:50:59.144263Z","iopub.execute_input":"2022-05-11T21:50:59.145619Z","iopub.status.idle":"2022-05-11T21:50:59.47885Z","shell.execute_reply.started":"2022-05-11T21:50:59.145569Z","shell.execute_reply":"2022-05-11T21:50:59.477742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fs_zcr,fs_rms = extract_features(df,1024,512)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:50:59.480605Z","iopub.execute_input":"2022-05-11T21:50:59.481265Z","iopub.status.idle":"2022-05-11T21:50:59.564726Z","shell.execute_reply.started":"2022-05-11T21:50:59.481213Z","shell.execute_reply":"2022-05-11T21:50:59.563724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(fs_rms[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:50:59.566523Z","iopub.execute_input":"2022-05-11T21:50:59.56712Z","iopub.status.idle":"2022-05-11T21:50:59.58787Z","shell.execute_reply.started":"2022-05-11T21:50:59.567058Z","shell.execute_reply":"2022-05-11T21:50:59.58641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ipd.Audio(audio_data)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:50:59.596188Z","iopub.execute_input":"2022-05-11T21:50:59.59688Z","iopub.status.idle":"2022-05-11T21:50:59.615351Z","shell.execute_reply.started":"2022-05-11T21:50:59.596813Z","shell.execute_reply":"2022-05-11T21:50:59.614409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"libd.waveshow(x,sr=sr, x_axis='time', color='cyan')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:50:59.619897Z","iopub.execute_input":"2022-05-11T21:50:59.620187Z","iopub.status.idle":"2022-05-11T21:50:59.99757Z","shell.execute_reply.started":"2022-05-11T21:50:59.620155Z","shell.execute_reply":"2022-05-11T21:50:59.99634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:50:59.998936Z","iopub.execute_input":"2022-05-11T21:50:59.999213Z","iopub.status.idle":"2022-05-11T21:51:00.005239Z","shell.execute_reply.started":"2022-05-11T21:50:59.99918Z","shell.execute_reply":"2022-05-11T21:51:00.003968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.007177Z","iopub.execute_input":"2022-05-11T21:51:00.007685Z","iopub.status.idle":"2022-05-11T21:51:00.021463Z","shell.execute_reply.started":"2022-05-11T21:51:00.007643Z","shell.execute_reply":"2022-05-11T21:51:00.020426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n0 = 9000\nn1 = 11048\nplt.figure(figsize=(14, 5))\nplt.plot(x[n0:n1])\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.022908Z","iopub.execute_input":"2022-05-11T21:51:00.02318Z","iopub.status.idle":"2022-05-11T21:51:00.260167Z","shell.execute_reply.started":"2022-05-11T21:51:00.023148Z","shell.execute_reply":"2022-05-11T21:51:00.259095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zero_crossings = librosa.zero_crossings(x[n0:n1], pad=False)\nprint(sum(zero_crossings))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.26139Z","iopub.execute_input":"2022-05-11T21:51:00.261634Z","iopub.status.idle":"2022-05-11T21:51:00.276337Z","shell.execute_reply.started":"2022-05-11T21:51:00.2616Z","shell.execute_reply":"2022-05-11T21:51:00.275084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zcr = librosa.feature.zero_crossing_rate(x,hop_length = 1024)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.27773Z","iopub.execute_input":"2022-05-11T21:51:00.278526Z","iopub.status.idle":"2022-05-11T21:51:00.28538Z","shell.execute_reply.started":"2022-05-11T21:51:00.27847Z","shell.execute_reply":"2022-05-11T21:51:00.284063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(zcr.size)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.286757Z","iopub.execute_input":"2022-05-11T21:51:00.287191Z","iopub.status.idle":"2022-05-11T21:51:00.29824Z","shell.execute_reply.started":"2022-05-11T21:51:00.287143Z","shell.execute_reply":"2022-05-11T21:51:00.297235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Padding mfcc_feature_space","metadata":{}},{"cell_type":"code","source":"max_len_mfcc = max([len(x[0]) for x in mfcc_feature_space])\n\nmfcc_feature_space = [np.pad(x, ((0,0),(0, max_len_mfcc - (x.shape[1]))), 'constant') for x in mfcc_feature_space]\n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.299531Z","iopub.execute_input":"2022-05-11T21:51:00.299919Z","iopub.status.idle":"2022-05-11T21:51:00.314906Z","shell.execute_reply.started":"2022-05-11T21:51:00.299881Z","shell.execute_reply":"2022-05-11T21:51:00.313916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Padding Zero Crossing Rate Feature Space","metadata":{}},{"cell_type":"code","source":"max_len_zcr = max([len(x) for x in fs_zcr])\nfs_zcr = [np.pad(x,(0, max_len_zcr - (len(x))), 'constant') for x in fs_zcr]\nfs_zcr=[x.astype('float32') for x in fs_zcr]","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.316102Z","iopub.execute_input":"2022-05-11T21:51:00.316375Z","iopub.status.idle":"2022-05-11T21:51:00.329329Z","shell.execute_reply.started":"2022-05-11T21:51:00.316329Z","shell.execute_reply":"2022-05-11T21:51:00.328218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Padding Energy Feature Space","metadata":{}},{"cell_type":"code","source":"max_len_rms = max([len(x) for x in fs_rms])\nfs_rms = [np.pad(x,(0, max_len_rms - (len(x))), 'constant') for x in fs_rms]","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.330942Z","iopub.execute_input":"2022-05-11T21:51:00.331781Z","iopub.status.idle":"2022-05-11T21:51:00.343821Z","shell.execute_reply.started":"2022-05-11T21:51:00.33174Z","shell.execute_reply":"2022-05-11T21:51:00.342769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting and Balancing the Data","metadata":{}},{"cell_type":"code","source":"from collections import Counter\ndef split_and_balance(data,labels):\n  s=Counter(labels)\n  x=min(s,key=s.get)\n  length_if_each_list=s[x];\n  list0=[]\n  list1=[]\n  list2=[]\n  list3=[]\n  list4=[]\n  list5=[]\n  list6=[]\n  for i in range(len(labels)):\n    if labels[i]==0 and len(list0)<length_if_each_list :\n      list0.append(data[i])\n    elif labels[i]==1 and len(list1)<length_if_each_list :\n      list1.append(data[i])\n    elif labels[i]==2 and len(list2)<length_if_each_list :\n      list2.append(data[i])\n    elif labels[i]==3 and len(list3)<length_if_each_list :\n      list3.append(data[i])\n    elif labels[i]==4 and len(list4)<length_if_each_list :\n      list4.append(data[i])\n    elif labels[i]==5 and len(list5)<length_if_each_list :\n      list5.append(data[i])\n\n  list_label0 = [ 0 for iter in range(length_if_each_list)]\n  list_label1 = [ 1 for iter in range(length_if_each_list)]\n  list_label2 = [ 2 for iter in range(length_if_each_list)]\n  list_label3 = [ 3 for iter in range(length_if_each_list)]\n  list_label4 = [ 4 for iter in range(length_if_each_list)]\n  list_label5 = [ 5 for iter in range(length_if_each_list)]\n    \n  return list0+list1+list2+list3+list4+list5,list_label0+list_label1+list_label2+list_label3+list_label4+list_label5","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.344999Z","iopub.execute_input":"2022-05-11T21:51:00.345789Z","iopub.status.idle":"2022-05-11T21:51:00.362117Z","shell.execute_reply.started":"2022-05-11T21:51:00.345733Z","shell.execute_reply":"2022-05-11T21:51:00.361395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def append_data_and_labels(data,labels):\n    data_with_labels=[]\n    for i in range(len(labels)) :\n        data_with_labels.append([data[i],labels[i]])\n    return np.array(z)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.363593Z","iopub.execute_input":"2022-05-11T21:51:00.364147Z","iopub.status.idle":"2022-05-11T21:51:00.380806Z","shell.execute_reply.started":"2022-05-11T21:51:00.3641Z","shell.execute_reply":"2022-05-11T21:51:00.379664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_training_validation_mfcc,x_test_mfcc,y_training_validation_mfcc,y_test_mfcc = train_test_split(mfcc_feature_space,labels,test_size=0.3,random_state=70)\n\nx_training_mfcc,x_validation_mfcc,y_training_mfcc,y_validation_mfcc= train_test_split(x_training_validation_mfcc,y_training_validation_mfcc,test_size=0.05,random_state=70)\n\n\nx_training_validation_zcr,x_test_zcr,y_training_validation_zcr,y_test_zcr = train_test_split(fs_zcr,labels,test_size=0.3,random_state=70)\nx_training_zcr,x_validation_zcr,y_training_zcr,y_validation_zcr= train_test_split(x_training_validation_zcr,y_training_validation_zcr,test_size=0.05,random_state=70)\n\nx_training_validation_rms,x_test_rms,y_training_validation_rms,y_test_rms = train_test_split(fs_rms,labels,test_size=0.3,random_state=70)\nx_training_rms,x_validation_rms,y_training_rms,y_validation_rms= train_test_split(x_training_validation_rms,y_training_validation_rms,test_size=0.05,random_state=70)\n\n#x_training_mfcc,y_training_mfcc=split_and_balance(x_training_mfcc,y_training_mfcc)\n#x_test_mfcc,y_test_mfcc=split_and_balance(x_test_mfcc,y_test_mfcc)\n#x_validation_mfcc,y_validation_mfcc=split_and_balance(x_validation_mfcc,y_validation_mfcc)\n\n#training_dataset_mfcc=append_data_and_labels(x_training_mfcc,y_training_mfcc)\n#test_dataset_mfcc=append_data_and_labels(x_test_mfcc,y_test_mfcc)\n#validation_dataset_mfcc=append_data_and_labels(x_validation_mfcc,y_validation_mfcc)\n\n\n#x_training_fs,y_training_fs=split_and_balance(x_training_fs,y_training_fs)\n#x_test_fs,y_test_fs=split_and_balance(x_test_fs,y_test_fs)\n#x_validation_fs,y_validation_fs=split_and_balance(x_validation_fs,y_validation_fs)\n\n#training_dataset_fs=append_data_and_labels(x_training_fs,y_training_fs)\n#test_dataset_fs=append_data_and_labels(x_test_fs,y_test_fs)\n#validation_dataset_fs=append_data_and_labels(x_validation_fs,y_validation_fs)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.382147Z","iopub.execute_input":"2022-05-11T21:51:00.382793Z","iopub.status.idle":"2022-05-11T21:51:00.402302Z","shell.execute_reply.started":"2022-05-11T21:51:00.382757Z","shell.execute_reply":"2022-05-11T21:51:00.401284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neural Network Architecture","metadata":{}},{"cell_type":"code","source":"# Define relevant variables for the ML task\nbatch_size = 64\nnum_classes = 6\nlearning_rate = 0.001\nnum_epochs = 10\n\n# Device will determine whether to run the training on GPU or CPU.\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.403733Z","iopub.execute_input":"2022-05-11T21:51:00.403991Z","iopub.status.idle":"2022-05-11T21:51:00.419458Z","shell.execute_reply.started":"2022-05-11T21:51:00.403961Z","shell.execute_reply":"2022-05-11T21:51:00.418064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a CNN class\nclass ConvNeuralNet2D(nn.Module):\n\t#  Determine what layers and their order in CNN object \n    def __init__(self, num_classes):\n        super(ConvNeuralNet2D, self).__init__()\n        self.conv_layer1 = nn.Conv2d(in_channels=1, out_channels=512, kernel_size=5,stride=1)\n        \n        self.relu1 = nn.ReLU()\n        \n        self.max_pool1 = nn.MaxPool2d(kernel_size = 5, stride = 2)\n        \n        self.conv_layer2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=5,stride=1)\n        \n        self.relu2 = nn.ReLU()\n        \n        self.max_pool2 = nn.MaxPool2d(kernel_size = 5, stride = 2)\n        \n        self.conv_layer3 = nn.Conv2d(in_channels=512, out_channels=128, kernel_size=5,stride=1)\n        \n        self.relu3 = nn.ReLU()\n        \n        self.max_pool3 = nn.MaxPool2d(kernel_size = 5, stride = 2)\n        \n        self.fc1 = nn.LazyLinear(256)\n        \n        self.relu4 = nn.ReLU()\n        \n        self.fc2 = nn.Linear(256, num_classes)\n        \n        self.dropout = nn.Dropout(p=0.5,inplace=False)\n        \n        \n    \n    # Progresses data across layers    \n    def forward(self, x):\n        out = self.conv_layer1(x)\n        \n        out=  self.relu1(out)\n        \n        #out = self.max_pool1(out)\n        \n        out = self.conv_layer2(out)\n        \n        out=self.relu2(out)\n        \n        #out=self.max_pool2(out)\n        \n        out = self.conv_layer3(out)\n        \n        out=self.relu3(out)\n        \n        #out = self.max_pool3(out)\n                \n        out = out.reshape(out.size(0), -1)\n        \n        out= self.dropout(out)\n        \n        out = self.fc1(out)\n        \n        out = self.relu4(out)\n        \n        out= self.dropout(out)\n        \n        out = self.fc2(out)\n        \n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.421019Z","iopub.execute_input":"2022-05-11T21:51:00.421482Z","iopub.status.idle":"2022-05-11T21:51:00.440788Z","shell.execute_reply.started":"2022-05-11T21:51:00.421434Z","shell.execute_reply":"2022-05-11T21:51:00.439793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a CNN class\nclass ConvNeuralNet1D(nn.Module):\n\t#  Determine what layers and their order in CNN object \n    def __init__(self, num_classes):\n        super(ConvNeuralNet1D, self).__init__()\n        self.conv_layer1 = nn.Conv1d(in_channels=1, out_channels=512, kernel_size=5,stride=1)\n        \n        self.relu1 = nn.ReLU()\n        \n        self.max_pool1 = nn.MaxPool1d(kernel_size = 5, stride = 2)\n        \n        self.conv_layer2 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=5,stride=1)\n        \n        self.relu2 = nn.ReLU()\n        \n        self.max_pool2 = nn.MaxPool1d(kernel_size = 5, stride = 2)\n        \n        self.conv_layer3 = nn.Conv1d(in_channels=512, out_channels=128, kernel_size=5,stride=1)\n        \n        self.relu3 = nn.ReLU()\n        \n        self.max_pool3 = nn.MaxPool1d(kernel_size = 5, stride = 2)\n        \n        self.fc1 = nn.LazyLinear(256)\n        \n        self.relu4 = nn.ReLU()\n        \n        self.fc2 = nn.Linear(256, num_classes)\n        \n        self.dropout = nn.Dropout(p=0.5,inplace=False)\n        \n\n    \n    # Progresses data across layers    \n    def forward(self, x):\n        out = self.conv_layer1(x)\n        \n        out=  self.relu1(out)\n        #out = self.max_pool1(out)\n        \n        out = self.conv_layer2(out)\n        \n        out=self.relu2(out)\n        \n        #out=self.max_pool2(out)\n        \n        out = self.conv_layer3(out)\n        \n        out=self.relu3(out)\n        \n        #out = self.max_pool3(out)\n                \n        out = out.reshape(out.size(0), -1)\n        \n        out= self.dropout(out)\n        \n        out = self.fc1(out)\n        \n        out = self.relu4(out)\n        \n        out= self.dropout(out)\n        \n        out = self.fc2(out)\n        \n       \n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.442197Z","iopub.execute_input":"2022-05-11T21:51:00.442558Z","iopub.status.idle":"2022-05-11T21:51:00.464102Z","shell.execute_reply.started":"2022-05-11T21:51:00.442521Z","shell.execute_reply":"2022-05-11T21:51:00.462897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Dataset Class","metadata":{}},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n\n    def __init__(self, data,labels):\n        \n        self.labels = torch.tensor(labels)\n        \n        self.audios = torch.tensor(data)\n        self.audios=self.audios.unsqueeze(1)\n\n    def classes(self):\n        return self.labels #Return the labels\n \n    def __len__(self):\n        return len(self.labels)#Return the number of labels\n\n    def get_batch_labels(self, idx):\n        # Fetch a batch of labels\n        return np.array(self.labels[idx])\n\n    def get_batch_audios(self, idx):\n        # Fetch a batch of inputs\n        return self.audios[idx]\n\n    def __getitem__(self, idx):\n\n        batch_audios = self.get_batch_audios(idx)#Return a batch of labels\n        batch_y = self.get_batch_labels(idx)#Return a batch of reviews\n\n        return batch_audios, batch_y","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.465843Z","iopub.execute_input":"2022-05-11T21:51:00.466196Z","iopub.status.idle":"2022-05-11T21:51:00.484927Z","shell.execute_reply.started":"2022-05-11T21:51:00.466142Z","shell.execute_reply":"2022-05-11T21:51:00.483811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_accuracy(y_test,y_predicted):\n \n    no_correct_samples=(y_predicted==y_test).sum().float()\n\n    return no_correct_samples","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.489975Z","iopub.execute_input":"2022-05-11T21:51:00.490763Z","iopub.status.idle":"2022-05-11T21:51:00.502829Z","shell.execute_reply.started":"2022-05-11T21:51:00.490701Z","shell.execute_reply":"2022-05-11T21:51:00.501868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_metrics(y_true,y_pred,labels):\n    x=f1_score(y_true,y_pred,average=\"weighted\")\n    print(\"Weigted Average F-Score is \",x)\n    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,labels=[0,1,2,3,4,5],display_labels=labels)\n   ","metadata":{"execution":{"iopub.status.busy":"2022-05-11T22:03:02.830519Z","iopub.execute_input":"2022-05-11T22:03:02.831801Z","iopub.status.idle":"2022-05-11T22:03:02.837296Z","shell.execute_reply.started":"2022-05-11T22:03:02.831718Z","shell.execute_reply":"2022-05-11T22:03:02.836587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model,train,val):\n    \n    # Set Loss function with criterion\n    criterion = nn.CrossEntropyLoss()\n    # Set optimizer with optimizer\n    optimizer = Adam(model.parameters(), lr= learning_rate)\n    train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)#While training a model,pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting\n    val_dataloader = torch.utils.data.DataLoader(val, batch_size=batch_size)\n    \n\n    # We use the pre-defined number of epochs to determine how many iterations to train the network on\n    for epoch in range(num_epochs):\n        total_acc_train = 0\n        total_loss_train = 0\n        #Load in the data in batches using the train_loader object\n        for (audios, labels) in tqdm(train_dataloader):  \n            # Move tensors to the configured device\n            audios = audios.to(device)\n            labels = labels.to(device)\n\n            # Forward pass\n            outputs = model(audios)\n          \n            outputs=torch.nn.functional.softmax(outputs)\n            \n\n            loss = criterion(outputs, labels)\n\n            total_loss_train += loss.item()\n\n            outputs = torch.argmax(outputs,dim=1)\n\n            acc = calculate_accuracy(labels,outputs)\n\n            total_acc_train += acc\n\n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n\n        total_acc_val = 0\n        total_loss_val = 0\n\n        with torch.no_grad():# Disable gradient calculation.\n        #Model is being validated so there is no need to calculate gradients. It will reduce memory consumption for computations that would otherwise have requires_grad=True.\n\n            for val_audios, val_labels in val_dataloader:\n                val_labels = val_labels.to(device)\n                val_audios = val_audios.to(device)\n                outputs = model(val_audios)\n                \n                outputs=torch.nn.functional.softmax(outputs)\n                \n                loss = criterion(outputs, val_labels)\n                total_loss_val += loss.item()\n                outputs = torch.argmax(outputs,dim=1)\n                acc = calculate_accuracy(val_labels,outputs)\n                total_acc_val += acc\n\n        print(\n            f'Epochs: {epoch + 1} | Train Loss: {total_loss_train / len(train): .3f} \\\n            | Train Accuracy: {total_acc_train / len(train): .3f} \\\n            | Val Loss: {total_loss_val / len(val): .3f} \\\n            | Val Accuracy: {total_acc_val / len(val): .3f}')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.517468Z","iopub.execute_input":"2022-05-11T21:51:00.518127Z","iopub.status.idle":"2022-05-11T21:51:00.535921Z","shell.execute_reply.started":"2022-05-11T21:51:00.518076Z","shell.execute_reply":"2022-05-11T21:51:00.53497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Melspectrogram","metadata":{}},{"cell_type":"code","source":"model=ConvNeuralNet2D(num_classes)\ntrain_data=Dataset(x_training_mfcc,y_training_mfcc)\nval=Dataset(x_validation_mfcc,y_validation_mfcc)            \ntrain(model,train_data,val)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:51:00.536973Z","iopub.execute_input":"2022-05-11T21:51:00.537771Z","iopub.status.idle":"2022-05-11T21:52:47.401153Z","shell.execute_reply.started":"2022-05-11T21:51:00.537725Z","shell.execute_reply":"2022-05-11T21:52:47.39955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Zero Crossing Rate","metadata":{}},{"cell_type":"code","source":"model=ConvNeuralNet1D(num_classes)\ntrain_data=Dataset(x_training_rms,y_training_rms)\nval=Dataset(x_validation_rms,y_validation_rms)            \ntrain(model,train_data,val)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:52:47.403274Z","iopub.execute_input":"2022-05-11T21:52:47.40373Z","iopub.status.idle":"2022-05-11T21:52:55.85037Z","shell.execute_reply.started":"2022-05-11T21:52:47.403674Z","shell.execute_reply":"2022-05-11T21:52:55.849225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Energy","metadata":{}},{"cell_type":"code","source":"model=ConvNeuralNet1D(num_classes)\ntrain_data=Dataset(x_training_zcr,y_training_zcr)\nval=Dataset(x_validation_zcr,y_validation_zcr)            \ntrain(model,train_data,val)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:52:55.852321Z","iopub.execute_input":"2022-05-11T21:52:55.85292Z","iopub.status.idle":"2022-05-11T21:53:05.130752Z","shell.execute_reply.started":"2022-05-11T21:52:55.852864Z","shell.execute_reply":"2022-05-11T21:53:05.129783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model,test_data,test_labels):\n\n    test = Dataset(test_data,test_labels)\n\n    test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size)\n\n\n    total_acc_test = 0\n    y_pred = []\n    y_pred=torch.tensor(y_pred)\n    y_pred=y_pred.to(device)\n    \n    with torch.no_grad():\n\n        for test_input, test_label in test_dataloader:\n\n            test_label = test_label.to(device)\n            test_input = test_input.to(device)\n            \n            outputs = model(test_input)\n            outputs=torch.nn.functional.softmax(outputs)\n            outputs = torch.argmax(outputs,dim=1)\n            y_pred=torch.cat((y_pred,outputs))\n            \n            acc = calculate_accuracy(test_label,outputs)\n              \n            total_acc_test += acc\n        \n            \n            print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n        \n        labels=emotions = ['SAD','ANG','DIS','FEA','HAP','NEU']\n        calculate_metrics(test_labels,y_pred,labels)\n\n#         test_data['sentiment'].replace({'positive':1,'negative':0},inplace=True)\n#         y_test=test_data['sentiment'].to_numpy()\n#         y_pred=torch.flatten(y_pred)\n#         y_pred=y_pred.detach().cpu().numpy()\n#         y_pred=np.where(y_pred > 0.5, 1, 0)\n#         classes=['negative','positive']\n        \n        \n#         net_classification_report=classification_report(y_test,y_pred,target_names=classes)    \n#         print(net_classification_report)\n#         conf_mat=confusion_matrix(y_test,y_pred)\n\n        \n#         disp=ConfusionMatrixDisplay(confusion_matrix=conf_mat,display_labels=classes)\n#         disp.plot()\n#         plt.show()\n\n#         gc.collect()\n    \n\n# #Load Best Model\n# PATH='model.pt'\n# checkpoint = torch.load(PATH)\n# model.load_state_dict(checkpoint['model_state_dict'])\n# #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n# epoch = checkpoint['epoch']\n# loss = checkpoint['loss']\n# #print the best model parameters\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:53:05.133421Z","iopub.execute_input":"2022-05-11T21:53:05.133682Z","iopub.status.idle":"2022-05-11T21:53:05.146779Z","shell.execute_reply.started":"2022-05-11T21:53:05.133651Z","shell.execute_reply":"2022-05-11T21:53:05.145468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing On Melspectrogram","metadata":{}},{"cell_type":"code","source":"model=ConvNeuralNet2D(num_classes)\nevaluate(model,x_test_mfcc,y_test_mfcc)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T22:03:07.341382Z","iopub.execute_input":"2022-05-11T22:03:07.341862Z","iopub.status.idle":"2022-05-11T22:03:09.583476Z","shell.execute_reply.started":"2022-05-11T22:03:07.34181Z","shell.execute_reply":"2022-05-11T22:03:09.582548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing On Zero Crossing Rate","metadata":{}},{"cell_type":"code","source":"model=ConvNeuralNet1D(num_classes)\nevaluate(model,x_test_zcr,y_test_zcr)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T22:03:11.616127Z","iopub.execute_input":"2022-05-11T22:03:11.616488Z","iopub.status.idle":"2022-05-11T22:03:12.102611Z","shell.execute_reply.started":"2022-05-11T22:03:11.616449Z","shell.execute_reply":"2022-05-11T22:03:12.101538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing On Energy","metadata":{}},{"cell_type":"code","source":"model=ConvNeuralNet1D(num_classes)\nevaluate(model,x_test_rms,y_test_rms)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T22:03:14.649465Z","iopub.execute_input":"2022-05-11T22:03:14.650019Z","iopub.status.idle":"2022-05-11T22:03:15.149441Z","shell.execute_reply.started":"2022-05-11T22:03:14.649986Z","shell.execute_reply":"2022-05-11T22:03:15.14724Z"},"trusted":true},"execution_count":null,"outputs":[]}]}